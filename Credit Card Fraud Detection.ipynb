{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ce74aa",
   "metadata": {},
   "source": [
    "A credit card is a small thin plastic or fiber card that incorporates information about the person such as a picture or signature and the person named on it to charge purchases and services to his linked account charges which will be debited regularly.   \n",
    "Nowadays, card data is read by ATMs, swiping machines, store readers, banks, and online transactions.  \n",
    "Each card has a unique card number which is very important, its security mainly relies on the physical security of the card and also the privacy of the credit card number.  \n",
    "There is a rapid growth in credit card transactions which has led to substantial growth in scam cases.  \n",
    "Credit card fraud is expanding heavily because fraud financial loss is increasing drastically.  \n",
    "Multiple data mining and statistical techniques are used to catch fraud.  \n",
    "Therefore the detection of fraud using efficient and secured methods are very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6165db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset.\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\ADMIN\\Downloads\\sm\\project\\8 Credit Card Fraud\\creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17abdd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11665, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c03023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11665 entries, 0 to 11664\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    11665 non-null  int64  \n",
      " 1   V1      11665 non-null  float64\n",
      " 2   V2      11665 non-null  float64\n",
      " 3   V3      11665 non-null  float64\n",
      " 4   V4      11665 non-null  float64\n",
      " 5   V5      11665 non-null  float64\n",
      " 6   V6      11665 non-null  float64\n",
      " 7   V7      11665 non-null  float64\n",
      " 8   V8      11665 non-null  float64\n",
      " 9   V9      11665 non-null  float64\n",
      " 10  V10     11665 non-null  float64\n",
      " 11  V11     11665 non-null  float64\n",
      " 12  V12     11664 non-null  float64\n",
      " 13  V13     11664 non-null  float64\n",
      " 14  V14     11664 non-null  float64\n",
      " 15  V15     11664 non-null  float64\n",
      " 16  V16     11664 non-null  float64\n",
      " 17  V17     11664 non-null  float64\n",
      " 18  V18     11664 non-null  float64\n",
      " 19  V19     11664 non-null  float64\n",
      " 20  V20     11664 non-null  float64\n",
      " 21  V21     11664 non-null  float64\n",
      " 22  V22     11664 non-null  float64\n",
      " 23  V23     11664 non-null  float64\n",
      " 24  V24     11664 non-null  float64\n",
      " 25  V25     11664 non-null  float64\n",
      " 26  V26     11664 non-null  float64\n",
      " 27  V27     11664 non-null  float64\n",
      " 28  V28     11664 non-null  float64\n",
      " 29  Amount  11664 non-null  float64\n",
      " 30  Class   11664 non-null  float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking for any missing values and data type of each column.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde6bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values rows\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773322f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11664 entries, 0 to 11663\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    11664 non-null  int64  \n",
      " 1   V1      11664 non-null  float64\n",
      " 2   V2      11664 non-null  float64\n",
      " 3   V3      11664 non-null  float64\n",
      " 4   V4      11664 non-null  float64\n",
      " 5   V5      11664 non-null  float64\n",
      " 6   V6      11664 non-null  float64\n",
      " 7   V7      11664 non-null  float64\n",
      " 8   V8      11664 non-null  float64\n",
      " 9   V9      11664 non-null  float64\n",
      " 10  V10     11664 non-null  float64\n",
      " 11  V11     11664 non-null  float64\n",
      " 12  V12     11664 non-null  float64\n",
      " 13  V13     11664 non-null  float64\n",
      " 14  V14     11664 non-null  float64\n",
      " 15  V15     11664 non-null  float64\n",
      " 16  V16     11664 non-null  float64\n",
      " 17  V17     11664 non-null  float64\n",
      " 18  V18     11664 non-null  float64\n",
      " 19  V19     11664 non-null  float64\n",
      " 20  V20     11664 non-null  float64\n",
      " 21  V21     11664 non-null  float64\n",
      " 22  V22     11664 non-null  float64\n",
      " 23  V23     11664 non-null  float64\n",
      " 24  V24     11664 non-null  float64\n",
      " 25  V25     11664 non-null  float64\n",
      " 26  V26     11664 non-null  float64\n",
      " 27  V27     11664 non-null  float64\n",
      " 28  V28     11664 non-null  float64\n",
      " 29  Amount  11664 non-null  float64\n",
      " 30  Class   11664 non-null  float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Again checking for any missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da24162",
   "metadata": {},
   "source": [
    "No missing values exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b8b6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "      <td>11664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7700.038923</td>\n",
       "      <td>-0.219749</td>\n",
       "      <td>0.275054</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.281090</td>\n",
       "      <td>-0.078968</td>\n",
       "      <td>0.140066</td>\n",
       "      <td>-0.111568</td>\n",
       "      <td>-0.051870</td>\n",
       "      <td>0.893578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061180</td>\n",
       "      <td>-0.155205</td>\n",
       "      <td>-0.034310</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>0.070630</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>62.795132</td>\n",
       "      <td>0.004201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5964.152936</td>\n",
       "      <td>1.561107</td>\n",
       "      <td>1.305821</td>\n",
       "      <td>1.272534</td>\n",
       "      <td>1.468011</td>\n",
       "      <td>1.184380</td>\n",
       "      <td>1.305527</td>\n",
       "      <td>1.129291</td>\n",
       "      <td>1.237045</td>\n",
       "      <td>1.182180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902556</td>\n",
       "      <td>0.624275</td>\n",
       "      <td>0.508488</td>\n",
       "      <td>0.592137</td>\n",
       "      <td>0.429725</td>\n",
       "      <td>0.560307</td>\n",
       "      <td>0.406841</td>\n",
       "      <td>0.262342</td>\n",
       "      <td>179.816783</td>\n",
       "      <td>0.064681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.670569</td>\n",
       "      <td>-34.607649</td>\n",
       "      <td>-21.405836</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-7.175097</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.468435</td>\n",
       "      <td>-8.555808</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-3.575312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2463.000000</td>\n",
       "      <td>-0.987263</td>\n",
       "      <td>-0.256929</td>\n",
       "      <td>0.416376</td>\n",
       "      <td>-0.615559</td>\n",
       "      <td>-0.680729</td>\n",
       "      <td>-0.622467</td>\n",
       "      <td>-0.583650</td>\n",
       "      <td>-0.186433</td>\n",
       "      <td>0.181498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268948</td>\n",
       "      <td>-0.545531</td>\n",
       "      <td>-0.172765</td>\n",
       "      <td>-0.332771</td>\n",
       "      <td>-0.146729</td>\n",
       "      <td>-0.346888</td>\n",
       "      <td>-0.080638</td>\n",
       "      <td>-0.015513</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6308.000000</td>\n",
       "      <td>-0.347859</td>\n",
       "      <td>0.263103</td>\n",
       "      <td>0.950089</td>\n",
       "      <td>0.215481</td>\n",
       "      <td>-0.179583</td>\n",
       "      <td>-0.147979</td>\n",
       "      <td>-0.088459</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.880714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130094</td>\n",
       "      <td>-0.129191</td>\n",
       "      <td>-0.044523</td>\n",
       "      <td>0.073145</td>\n",
       "      <td>0.139638</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>-0.003818</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11896.500000</td>\n",
       "      <td>1.159313</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>1.616290</td>\n",
       "      <td>1.153440</td>\n",
       "      <td>0.348249</td>\n",
       "      <td>0.509058</td>\n",
       "      <td>0.439539</td>\n",
       "      <td>0.267141</td>\n",
       "      <td>1.570372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.235448</td>\n",
       "      <td>0.076761</td>\n",
       "      <td>0.402522</td>\n",
       "      <td>0.374859</td>\n",
       "      <td>0.417677</td>\n",
       "      <td>0.108443</td>\n",
       "      <td>0.073961</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19915.000000</td>\n",
       "      <td>1.960497</td>\n",
       "      <td>9.067613</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>11.927512</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>5.499963</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>...</td>\n",
       "      <td>22.599543</td>\n",
       "      <td>4.534454</td>\n",
       "      <td>13.876221</td>\n",
       "      <td>3.200201</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>8.254376</td>\n",
       "      <td>4.860769</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  11664.000000  11664.000000  11664.000000  11664.000000  11664.000000   \n",
       "mean    7700.038923     -0.219749      0.275054      0.898063      0.281090   \n",
       "std     5964.152936      1.561107      1.305821      1.272534      1.468011   \n",
       "min        0.000000    -27.670569    -34.607649    -21.405836     -4.657545   \n",
       "25%     2463.000000     -0.987263     -0.256929      0.416376     -0.615559   \n",
       "50%     6308.000000     -0.347859      0.263103      0.950089      0.215481   \n",
       "75%    11896.500000      1.159313      0.888821      1.616290      1.153440   \n",
       "max    19915.000000      1.960497      9.067613      4.101716     11.927512   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  11664.000000  11664.000000  11664.000000  11664.000000  11664.000000   \n",
       "mean      -0.078968      0.140066     -0.111568     -0.051870      0.893578   \n",
       "std        1.184380      1.305527      1.129291      1.237045      1.182180   \n",
       "min      -32.092129    -23.496714    -26.548144    -23.632502     -7.175097   \n",
       "25%       -0.680729     -0.622467     -0.583650     -0.186433      0.181498   \n",
       "50%       -0.179583     -0.147979     -0.088459      0.011706      0.880714   \n",
       "75%        0.348249      0.509058      0.439539      0.267141      1.570372   \n",
       "max       34.099309     21.393069     34.303177      5.499963     10.392889   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  11664.000000  11664.000000  11664.000000  11664.000000   \n",
       "mean   ...     -0.061180     -0.155205     -0.034310      0.017421   \n",
       "std    ...      0.902556      0.624275      0.508488      0.592137   \n",
       "min    ...    -11.468435     -8.555808    -19.254328     -2.512377   \n",
       "25%    ...     -0.268948     -0.545531     -0.172765     -0.332771   \n",
       "50%    ...     -0.130094     -0.129191     -0.044523      0.073145   \n",
       "75%    ...      0.023295      0.235448      0.076761      0.402522   \n",
       "max    ...     22.599543      4.534454     13.876221      3.200201   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  11664.000000  11664.000000  11664.000000  11664.000000  11664.000000   \n",
       "mean       0.101538      0.070630      0.007481      0.000804     62.795132   \n",
       "std        0.429725      0.560307      0.406841      0.262342    179.816783   \n",
       "min       -4.781606     -1.338556     -7.976100     -3.575312      0.000000   \n",
       "25%       -0.146729     -0.346888     -0.080638     -0.015513      5.000000   \n",
       "50%        0.139638      0.009023     -0.003818      0.015397     15.950000   \n",
       "75%        0.374859      0.417677      0.108443      0.073961     50.000000   \n",
       "max        5.525093      3.517346      8.254376      4.860769   7712.430000   \n",
       "\n",
       "              Class  \n",
       "count  11664.000000  \n",
       "mean       0.004201  \n",
       "std        0.064681  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate descriptive statistics of a pandas DataFrame.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8074c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Genuine transactions:  11615\n",
      "Number of Fraud transactions:  49\n",
      "Percentage of Fraud transactions: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of genuine/fraud transactions and percentage of fraud transactions.\n",
    "non_fraud = len(df[df.Class == 0])\n",
    "fraud = len(df[df.Class == 1])\n",
    "fraud_percent = float((fraud / (fraud + non_fraud)) * 100)\n",
    "print(\"Number of Genuine transactions: \", non_fraud)\n",
    "print(\"Number of Fraud transactions: \", fraud)\n",
    "print(f\"Percentage of Fraud transactions: {fraud_percent:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2427ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the genuine and fraudulent transactions using a bar graph.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10, 4))\n",
    "df['Class'].value_counts().plot(kind='bar', rot=0, color='lightgreen', edgecolor='black')\n",
    "plt.title('Visualization of Labels', fontdict={'fontsize': 14, 'fontweight': 'bold', 'color': 'blue'})\n",
    "plt.ylabel('Count', fontdict={'fontsize': 10, 'fontweight': 'normal', 'color': 'red'})\n",
    "plt.xticks(range(2), ['Genuine', 'Fraud'], fontdict={'fontsize': 10, 'fontweight': 'normal', 'color': 'purple'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f027e",
   "metadata": {},
   "source": [
    "#### Standard Scalar\n",
    "StandardScaler is a class from the sklearn.preprocessing module in scikit-learn library. It is used for standardizing features by removing the mean and scaling to unit variance. Standardization is a common preprocessing step for machine learning algorithms, as it can help improve the performance and stability of the model.\n",
    "\n",
    "In more detail, StandardScaler works by first calculating the mean and standard deviation of each feature in the dataset. It then subtracts the mean from each feature value and divides the result by the standard deviation, which scales the data to have a mean of zero and a variance of one. This process can help prevent features with larger scales from dominating the learning process and can make it easier to compare the relative importance of different features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0ccfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Standard Scaler module, normalize the amount column and store the new values in the NormalizedAmount column.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df[\"NormalizedAmount\"] = scaler.fit_transform(df[\"Amount\"].values.reshape(-1, 1))\n",
    "df.drop([\"Amount\", \"Time\"], inplace= True, axis= 1)\n",
    "X = df.drop([\"Class\"], axis= 1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557a1ec",
   "metadata": {},
   "source": [
    "#### train_test_split\n",
    "train_test_split is a function from the sklearn.model_selection module in scikit-learn library. It is used to split a dataset into a training set and a testing set for machine learning.\n",
    "\n",
    "In more detail, the train_test_split() function randomly splits a dataset into two sets: a training set and a testing set. The training set is used to train a machine learning model, while the testing set is used to evaluate the model's performance on new, unseen data. The function takes several arguments, including the dataset to be split, the test size (the proportion of the dataset to be used for testing), and the random state (a seed value for the random number generator used to split the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9670cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (8164, 29)\n",
      "Shape of X_test:  (3500, 29)\n",
      "Shape of y_train:  (8164,)\n",
      "Shape of y_test:  (3500,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in train and test set and have a 70:30 split ratio for the model.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3000a",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ebbeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_y_pred : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Accuracy Score : 0.9991428571428571\n",
      "\n",
      "Confusion Matrix - Random Forest :\n",
      " [[3483    1]\n",
      " [   2   14]]\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3484\n",
      "         1.0       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           1.00      3500\n",
      "   macro avg       0.97      0.94      0.95      3500\n",
      "weighted avg       1.00      1.00      1.00      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using random forest model for training on top of the train set.\n",
    "# Calculate the prediction of model using predict().\n",
    "# Calculate the accuracy of model using score().\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 1000)\n",
    "rfc.fit(X_train, y_train).score(X_test, y_test)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(f\"RandomForestClassifier_y_pred : {y_pred[:20]}\\n\")\n",
    "print(f\"Accuracy Score : {accuracy_score(y_test, y_pred)}\\n\")\n",
    "print(f\"Confusion Matrix - Random Forest :\\n {confusion_matrix(y_test, y_pred)}\\n\")\n",
    "print(f\"Classification Report : \\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fae6e",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f049d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier_y_pred : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Accuracy Score : 0.9985714285714286\n",
      "\n",
      "Confusion Matrix - Decision Tree :\n",
      " [[3481    3]\n",
      " [   2   14]]\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3484\n",
      "         1.0       0.82      0.88      0.85        16\n",
      "\n",
      "    accuracy                           1.00      3500\n",
      "   macro avg       0.91      0.94      0.92      3500\n",
      "weighted avg       1.00      1.00      1.00      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using decision tree model for training on top of the train set.\n",
    "# Calculate the prediction of model using predict().\n",
    "# Calculate the accuracy of model using score().\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(f\"DecisionTreeClassifier_y_pred : {y_pred[:20]}\\n\")\n",
    "print(f\"Accuracy Score : {accuracy_score(y_test, y_pred)}\\n\")\n",
    "print(f\"Confusion Matrix - Decision Tree :\\n {confusion_matrix(y_test, y_pred)}\\n\")\n",
    "print(f\"Classification Report : \\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b257727",
   "metadata": {},
   "source": [
    "#### Check the performance matrix of both models and compare which model is having the highest performance.\n",
    "Accuracy, Precision, Recall & f1-score of Random Forest Model is higher than Decision Tree Model, so Random Forest Model is having highest performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a84eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
